{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3fdfee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hice1/apanda38/cs8803/final/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "from functools import partial\n",
    "from collections import OrderedDict\n",
    "from itertools import islice\n",
    "import numpy as np\n",
    "\n",
    "from more_itertools import chunked\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "from sae_lens import SAE\n",
    "import huggingface_hub\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "decffd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a3a084",
   "metadata": {},
   "source": [
    "## Gemma 2 2B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5ce23f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [02:34<00:00, 51.50s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Gemma2ForCausalLM(\n",
       "  (model): Gemma2Model(\n",
       "    (embed_tokens): Embedding(256000, 2304, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-25): 26 x Gemma2DecoderLayer(\n",
       "        (self_attn): Gemma2Attention(\n",
       "          (q_proj): Linear(in_features=2304, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2304, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=2304, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2304, bias=False)\n",
       "        )\n",
       "        (mlp): Gemma2MLP(\n",
       "          (gate_proj): Linear(in_features=2304, out_features=9216, bias=False)\n",
       "          (up_proj): Linear(in_features=2304, out_features=9216, bias=False)\n",
       "          (down_proj): Linear(in_features=9216, out_features=2304, bias=False)\n",
       "          (act_fn): GELUTanh()\n",
       "        )\n",
       "        (input_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "        (post_attention_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "        (pre_feedforward_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "        (post_feedforward_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "    (rotary_emb): Gemma2RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2304, out_features=256000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2-2b\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"google/gemma-2-2b\",\n",
    "    torch_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe584a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -c 'https://huggingface.co/google/gemma-scope-2b-pt-res/resolve/main/layer_20/width_16k/average_l0_71/params.npz' -O sae.npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a6a386c",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_dec = np.load(\"sae.npz\")[\"W_dec\"]\n",
    "layer = 20\n",
    "feat = torch.from_numpy(w_dec[12332]).cuda().to(torch.bfloat16)\n",
    "feat = 3 * (feat / feat.norm())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181c39ff",
   "metadata": {},
   "source": [
    "## Llama 3.1 8B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8efa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 20\n",
    "\n",
    "sae, cfg_dict, sparsity = SAE.from_pretrained(\n",
    "    release=\"llama_scope_lxr_8x\",\n",
    "    sae_id=f\"l{layer}r_8x\",\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8cf9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8205e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEAT = 10386\n",
    "\n",
    "feat = sae.state_dict()['W_dec'][FEAT].cuda().to(torch.bfloat16).reshape(1, 1, -1)\n",
    "feat = feat / feat.norm() * 15\n",
    "\n",
    "del sae, cfg_dict, sparsity\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d6c656",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.1-8B\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.1-8B\", torch_dtype=torch.bfloat16)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4734c88b",
   "metadata": {},
   "source": [
    "## Steering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b820b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"NeelNanda/pile-10k\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf6f7788",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 10000/16384 [00:25<00:16, 394.70it/s]\n"
     ]
    }
   ],
   "source": [
    "def add_vec(self, inp, out):\n",
    "    # out = out.clone()\n",
    "    # out += feat\n",
    "    # return out\n",
    "    return (out[0] + feat,) + out[1:]\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "bs = 32\n",
    "msl = 32\n",
    "start = 0\n",
    "take_n = 2**14\n",
    "\n",
    "n_processed = 0\n",
    "distribution = []\n",
    "greatest = []\n",
    "lowest = []\n",
    "\n",
    "@torch.inference_mode()\n",
    "@torch.compile\n",
    "def cent(x, y):\n",
    "    return -torch.gather(torch.nn.functional.log_softmax(x, dim=-1), -1, torch.nn.functional.relu(y.unsqueeze(-1)).roll(-1, -2)).sum(-1) * (y >= 0).roll(-1, -1) * (torch.arange(y.shape[-1]).to(y.device) < y.shape[-1] - 1)\n",
    "\n",
    "try:\n",
    "    for batch in chunked((bar := tqdm(islice(ds, start, start+take_n), total=take_n)), bs):\n",
    "        for m in model.modules():\n",
    "            m._forward_hooks = OrderedDict()\n",
    "        batch_txt = [x[\"text\"] for x in batch]\n",
    "        batch = torch.tensor(tokenizer.batch_encode_plus(batch_txt, max_length=msl, padding=True, truncation=True)[\"input_ids\"])\n",
    "        pad = batch == tokenizer.pad_token_id\n",
    "        batch[pad] = 0\n",
    "        labels = batch.clone()\n",
    "        labels[pad] = -100\n",
    "        labels = labels.cuda()\n",
    "        pad = pad.cuda()\n",
    "        with torch.inference_mode():\n",
    "            inputs = dict(input_ids=batch.cuda(), labels=labels.cuda())\n",
    "            logits = model(**inputs).logits.float()\n",
    "            loss1 = cent(logits, labels).mean(-1)\n",
    "            model.model.layers[layer].register_forward_hook(add_vec)\n",
    "            logits = model(**inputs).logits.float()\n",
    "            loss2 = cent(logits, labels).mean(-1)\n",
    "            losses = loss2 - loss1\n",
    "        addition = list(zip(losses.tolist(), batch_txt))\n",
    "        greatest.extend(addition)\n",
    "        lowest.extend(addition)\n",
    "        greatest.sort(reverse=True)\n",
    "        lowest.sort()\n",
    "        greatest = greatest[:20]\n",
    "        lowest = lowest[:20]\n",
    "        n_processed += bs\n",
    "        distribution.extend(addition)\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "022902c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.026980280876159668 '/*--------------------------------*- C++ -*----------------------------------*\\\\\\n  =========                 |\\n  \\\\\\\\      /  F ield         | OpenFOAM: The Open Source CFD Toolbox\\n   \\\\\\\\    /   O peratio'\n",
      "0.026227951049804688 'Comment by Loreanadruid\\n\\nArguably Inferior Socket for Paladin PvE Gems for the most part, but Superior for PvP.A side-grade to t6, but an upgrade for almost anything pre-Sunwell.\\n\\nComment by mikititan'\n",
      "0.025263309478759766 '364 F.3d 622\\nUNITED STATES of America, Plaintiff-Appellee,v.Osvaldo LOPEZ-CORONADO, Defendant-Appellant.\\nNo. 03-40666.\\nUnited States Court of Appeals, Fifth Circuit.\\nMarch 30, 2004.\\n\\nMitchel Neurock ('\n",
      "0.024628162384033203 'Q:\\n\\nGet data whenever email is sent to an email id and update db with email information\\n\\nI am trying to write a webservice and configure my webserver such that whenever I send an email to xyz@domain.c'\n",
      "0.023473501205444336 \"Q:\\n\\nIterating through linked objects, how to avoid duplicates\\n\\nI have an array of objects that are linked together by a unique id.\\nSomething like this:\\nvar nodes    = [];\\n    nodes[0] = {'id':1,'links\"\n",
      "0.02345895767211914 'The study is comparing the efficacy and safety of heater probe or injection therapy for ulcers (actively bleeding, non-bleeding vivible vessel, or adherent clots) versus medical-surgical treatment. Th'\n",
      "0.023400306701660156 'Q:\\n\\nRaw Socket Help: Why UDP packets created by raw sockets are not being received by kernel UDP?\\n\\nI am studying raw sockets. I used the IP_HDRINCL option to build my own IP headers. After the IP head'\n",
      "0.023022174835205078 '/*\\nCopyright (C) 2011 Mark Chandler (Desura Net Pty Ltd)\\nCopyright (C) 2014 Bad Juju Games, Inc.\\n\\nThis program is free software: you can redistribute it and/or modify\\nit under the terms of the GNU Gen'\n",
      "0.02272629737854004 \"Settler Theology & Israel's Future\\n\\nOver the years, the West Bank olive harvest has become an annual low-level battle, with settlers stealing from and ravaging Palestinian groves and with outpost sett\"\n",
      "0.022154808044433594 'Apache – “Crystal Clear” (mp3)\\n\\nTexas/Bay Area band Apache‘s sound is pushing upstream in a time when many bands are trying to tattoo a new sonic marker in the rock n’ roll landscape. They write catch'\n"
     ]
    }
   ],
   "source": [
    "for score, txt in greatest:\n",
    "    print(score, repr(txt[:200]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23e6a1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.027944087982177734 '5.9k SHARES Facebook Twitter Whatsapp Pinterest Reddit Print Mail Flipboard\\n\\nAdvertisements\\n\\nA public interest group has written to the Justice Department seeking a criminal investigation into Ben Car'\n",
      "-0.027001380920410156 'defmodule Absinthe.Execution.SubscriptionTest do\\n  use Absinthe.Case\\n\\n  import ExUnit.CaptureLog\\n\\n  defmodule PubSub do\\n    @behaviour Absinthe.Subscription.Pubsub\\n\\n    def start_link() do\\n      Regis'\n",
      "-0.024200439453125 'Pasi Rilindja dështoi që të sillte ashtu sikurse pati premtuar një analizë nga një laborator ndërkombëtar, për të thënë se përgjimi i Babales qe një manipulim, ajo përdori skenarin “B”. Krijimin e një'\n",
      "-0.022858858108520508 'Q:\\n\\nWhat tools can be used to find which DLLs are referenced?\\n\\nThis is an antique problem with VB6 DLL and COM objects but I still face it day to day. What tools or procedures can be used to see which'\n",
      "-0.02281332015991211 ' -i - 7 = -8*i. Calculate i*v(q) + 3*h(q).\\nq**3\\nLet k(p) = -20*p**3 + 17*p**2 + 23*p + 14. Let q(w) = w**3 - 18*w**2 - 17. Let j be q(18). Let v(n) = -7*n**3 + 6*n**2 + 8*n + 5. Give j*v(b) + 6*k(b).\\n'\n",
      "-0.022285938262939453 '\\n\\nAsk HN: Minority Report with NSA data?  - klasdfakaf\\n\\nJust a thought experiment. Can we prevent crimes from happening with NSA backed data? Can we use AI to predict the actions of individuals and th'\n",
      "-0.022188186645507812 'US\\n\\nAIPAC\\n\\nAIPAC\\n\\nIf there is something unique about this story it is the level of interest that it has generated. Neither spying, nor the influence peddling is new; but until professors John Mearshei'\n",
      "-0.02199077606201172 \"Q:\\n\\nTextField doesn't take input after adding 2 decimal positive numbers configuration in whitelistingtextinputformatter\\n\\n                keyboardType: TextInputType.number,\\n                inputForma\"\n",
      "-0.02187633514404297 'Parents and pupils to march on London as hundreds defend Sunderland free school\\n\\nA DELEGATION of 200 parents and children from Grindon Hall Christian School will march on London as they fight back at '\n",
      "-0.021520137786865234 'Từ ngày ta trở thành người gác mộ, ta đã biết đến nghĩa trang Lutz.\\nTa không được phép ngủ lại nơi đây\\nNhững người tốt thì được chôn cất nơi dây, còn quỷ dữ thì chôn xác bên ngoài\\nDối trá ! Tuy nhiên,'\n"
     ]
    }
   ],
   "source": [
    "for score, txt in lowest:\n",
    "    print(score, repr(txt[:200]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
